{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# XGB Regressor to predict revenue for Steam games\n",
    "# By Willyam Ramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads matrix ready for regression and final merged data\n",
    "X = pd.read_pickle(\"../data/processed/matrix_ready_for_regression.pkl\")\n",
    "data = pd.read_pickle(\"../data/processed/final_merged_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove F2P games (they have $0 revenue, not useful for prediction)\n",
    "# $0 revenue would skew the regression results by creating a large cluster of points at zero and attributing profitability to features that indicate F2P status\n",
    "\n",
    "y = data[\"log_estimated_revenue\"]\n",
    "mask_paid = X['f2p_flag'] == 0\n",
    "X_paid = X[mask_paid].copy()\n",
    "y_paid = y[mask_paid].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable in log scale\n",
    "X_paid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop f2p_flag and related features\n",
    "cols_to_drop = ['f2p_flag', 'peak_players', 'copies_sold_reviews_proxy', 'user_reviews']\n",
    "if 'Genres_Free To Play' in X_paid.columns:\n",
    "    cols_to_drop.append('Genres_Free To Play')\n",
    "\n",
    "X_paid = X_paid.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Original dataset: {len(X)} games\")\n",
    "print(f\"Paid games only: {len(X_paid)} games\")\n",
    "print(f\"Removed features: {cols_to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672dea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test) \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_paid, y_paid, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af395ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and trains the XGBoost regression model\n",
    "model = XGBRegressor(\n",
    "    n_estimators=500, # Number of trees\n",
    "    learning_rate=0.05, # Step size shrinkage, or how much each tree is allowed to correct the previous one\n",
    "    max_depth=8, # Maximum tree depth for base learners, not overall tree depth\n",
    "    subsample=0.8, # Trains each tree on 80% of the data to prevent overfitting\n",
    "    colsample_bytree=0.8, # Use 80% of the features for each tree\n",
    "    objective=\"reg:squarederror\", # Regression with squared loss\n",
    "    tree_method=\"hist\", # Histogram based algorithms are known to be faster for large datasets\n",
    "    random_state=42, \n",
    "    early_stopping_rounds=50,  # Stop training if no improvement in 50 rounds\n",
    "    eval_metric=\"rmse\" # Evaluation metric is Root Mean Squared Error (RMSE)\n",
    ")\n",
    "\n",
    "# X_train and y_train correspond to the dataset attributes and target variable\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Process: Build tree to predict y_train, then check performance on X_test and y_test, build another tree if not good enough, repeat until early stopping or max trees reached\n",
    "# Each tree can be thought of as a weak learner that corrects the errors of the previous trees and has a max depth of 8 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predicts LOG revenue, and we convert it back to actual revenue\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred_revenue = np.exp(y_pred_log) \n",
    "\n",
    "# Also convert actual values back to dollars for comparison\n",
    "y_test_revenue = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_log)) # RMSE on log scale \n",
    "mae_log = mean_absolute_error(y_test, y_pred_log) # MAE on log scale\n",
    "r2_log = r2_score(y_test, y_pred_log) # R² on log scale\n",
    "\n",
    "# Metrics on ACTUAL dollar scale (for interpretability), will be larger due to exponentiation\n",
    "rmse_actual = np.sqrt(mean_squared_error(y_test_revenue, y_pred_revenue))\n",
    "mae_actual = mean_absolute_error(y_test_revenue, y_pred_revenue)\n",
    "r2_actual = r2_score(y_test_revenue, y_pred_revenue)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"REGRESSION PERFORMANCE (Revenue Prediction)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nLog-Scale Metrics (what model optimizes):\")\n",
    "print(f\"  RMSE: {rmse_log:.4f}\")\n",
    "print(f\"  MAE:  {mae_log:.4f}\")\n",
    "print(f\"  R²:   {r2_log:.4f}\")\n",
    "\n",
    "print(\"\\nActual Dollar Metrics (for interpretation):\")\n",
    "print(f\"  RMSE: ${rmse_actual:,.2f}\")\n",
    "print(f\"  MAE:  ${mae_actual:,.2f}\")\n",
    "print(f\"  R²:   {r2_actual:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUCCESS_THRESHOLD = 100_000  \n",
    "\n",
    "LOG_SUCCESS_THRESHOLD = np.log1p(SUCCESS_THRESHOLD)\n",
    "\n",
    "# Produces boolean arrays indicating whether each game is a \"success\" based on the threshold\n",
    "y_test_success = (y_test >= LOG_SUCCESS_THRESHOLD).astype(int)\n",
    "y_pred_success = (y_pred_log >= LOG_SUCCESS_THRESHOLD).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dffff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (correct predictions / total predictions)\n",
    "accuracy = accuracy_score(y_test_success, y_pred_success)\n",
    "\n",
    "# Checks if we have both 0 and 1 in predictions and actuals\n",
    "unique_pred = np.unique(y_pred_success)\n",
    "unique_actual = np.unique(y_test_success)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"CLASSIFICATION PERFORMANCE (Success >= ${SUCCESS_THRESHOLD:,})\")\n",
    "print(f\"(Log threshold: {LOG_SUCCESS_THRESHOLD:.4f})\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prints how many rows passed the success threshold over total rows\n",
    "print(f\"\\nActual successes in test set: {y_test_success.sum()} / {len(y_test_success)} ({y_test_success.mean():.1%})\")\n",
    "print(f\"Predicted successes: {y_pred_success.sum()} / {len(y_pred_success)} ({y_pred_success.mean():.1%})\")\n",
    "\n",
    "# Convert back to original scale for interpretability\n",
    "y_test_revenue_display = np.expm1(y_test)\n",
    "print(f\"\\nRevenue distribution in test set (original scale):\")\n",
    "print(f\"  Min:     ${y_test_revenue_display.min():,.2f}\")\n",
    "print(f\"  25th %:  ${np.percentile(y_test_revenue_display, 25):,.2f}\")\n",
    "print(f\"  Median:  ${np.percentile(y_test_revenue_display, 50):,.2f}\")\n",
    "print(f\"  75th %:  ${np.percentile(y_test_revenue_display, 75):,.2f}\")\n",
    "print(f\"  Max:     ${y_test_revenue_display.max():,.2f}\")\n",
    "print(f\"  Mean:    ${y_test_revenue_display.mean():,.2f}\")\n",
    "\n",
    "# Only calculate metrics if both classes exist\n",
    "if len(unique_pred) > 1 and len(unique_actual) > 1:\n",
    "    # Precision = TP / (All positives predicted)\n",
    "    precision = precision_score(y_test_success, y_pred_success, zero_division=0)\n",
    "    # Recall = TP / (All actual positives)\n",
    "    recall = recall_score(y_test_success, y_pred_success, zero_division=0)\n",
    "    # F1 Score = 2 * (Precision * Recall) / (Precision + Recall); Measures the balance between precision and recall\n",
    "    f1 = f1_score(y_test_success, y_pred_success, zero_division=0)\n",
    "    cm = confusion_matrix(y_test_success, y_pred_success)\n",
    "    \n",
    "    print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f} (of predicted successes, % actually successful)\")\n",
    "    print(f\"Recall:    {recall:.4f} (of actual successes, % we caught)\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"               Fail  Success\")\n",
    "    print(f\"Actual Fail    {cm[0,0]:4d}    {cm[0,1]:4d}\")\n",
    "    print(f\"      Success  {cm[1,0]:4d}    {cm[1,1]:4d}\")\n",
    "else:\n",
    "    print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "    print(\"\\n⚠️  WARNING: Model predicts only one class!\")\n",
    "    print(f\"   Try adjusting SUCCESS_THRESHOLD (current: ${SUCCESS_THRESHOLD:,})\")\n",
    "    print(f\"   Revenue range in test set: ${y_test_revenue_display.min():,.2f} to ${y_test_revenue_display.max():,.2f}\")\n",
    "    print(f\"   Median revenue: ${np.median(y_test_revenue_display):,.2f}\")\n",
    "    print(f\"   Mean revenue: ${y_test_revenue_display.mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c225c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the top 20 most important features used by the model by importance score\n",
    "# By default, the importance is calculated based on the number of times a feature is used to split the data across all trees (weight)\n",
    "importances = pd.Series(model.feature_importances_, index=X_paid.columns)\n",
    "top20 = importances.sort_values(ascending=False).head(20)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "for feature, importance in top20.items():\n",
    "    print(f\"{feature:40s} {importance:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "top20.sort_values().plot(kind='barh')  # sort bottom-to-top for best readability\n",
    "\n",
    "plt.title(\"Top 20 Most Important Features (XGBoost)\")\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c8fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
